# Tasks: Infrastructure & Security - Hybrid Deployment Setup

**Input**: Design documents from `/specs/001-infrastructure-setup/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/, quickstart.md

**Tests**: Not required for infrastructure setup (acceptance tests via manual verification in user stories)

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

## Path Conventions

Based on plan.md project structure:
- **Backend**: `backend/src/`, `backend/prisma/`
- **Frontend**: `frontend/src/`
- **Infrastructure**: `infrastructure/`
- **Documentation**: `docs/infrastructure/`

---

## Phase 0: Planning

### P001: Task Analysis & Executor Assignment âœ… **COMPLETED (REVISED)**
**Description**: Ð”Ð¾ÑÐºÐ¾Ð½Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²ÑÐµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ñ‹ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð½Ð¾Ð²Ñ‹Ðµ
**Executor**: MAIN
**Dependencies**: None
**Rules**:
- [EXECUTOR: MAIN] - Ð¢ÐžÐ›Ð¬ÐšÐž Ñ‚Ñ€Ð¸Ð²Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ (1 ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°: mkdir, 1 npm install, prisma generate)
- Existing subagents - Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ 100% match Ð¿Ð¾ÑÐ»Ðµ Ñ‚Ñ‰Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
- [EXECUTOR: new-agent-name] - Ð•ÑÐ»Ð¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ ÐÐ• Ð¿Ð¾ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð½Ð° 100%

**Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÑÐ»Ðµ Ð¿ÐµÑ€ÐµÑÐ¼Ð¾Ñ‚Ñ€Ð°**:
- âœ… 3 ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ð° Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‚: database-architect, api-builder, technical-writer
- ðŸ†• 8 Ð½Ð¾Ð²Ñ‹Ñ… ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Ð¡ÐžÐ—Ð”ÐÐÐ« Ñ‡ÐµÑ€ÐµÐ· meta-agent-v3 (Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾):
  1. docker-compose-specialist
  2. nginx-ssl-specialist
  3. monitoring-stack-specialist
  4. nodejs-backend-initializer
  5. nextjs-frontend-initializer
  6. github-actions-specialist
  7. bash-scripts-specialist
  8. telegraf-bot-middleware-specialist

**Artifacts**:
- Updated tasks.md (this file)
- 8 Ð½Ð¾Ð²Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Ð² `.claude/agents/infrastructure/workers/`

### P002: Research Task Resolution âœ… **COMPLETED**
**Description**: Identify and resolve research questions (simple: solve now, complex: create prompts)
**Executor**: MAIN
**Dependencies**: P001
**Output**:
- Simple research: documented findings (already complete in research.md)
- Complex research: prompts in research/ directory (none needed - all decisions resolved)
**Status**: All research complete in research.md (13 technical decisions resolved)
**Artifacts**: research.md (already exists, no changes needed)

### P003: Meta-Agent Subagent Creation âœ… **COMPLETED**
**Description**: Create FUTURE agents using meta-agent-v3, then ask user to restart claude-code
**Executor**: meta-agent-v3 (8 Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²)
**Dependencies**: P001
**Execution**: Launched 8 meta-agent-v3 calls in single message (parallel creation)
**Status**: âœ… **COMPLETED** - 8 Ð½Ð¾Ð²Ñ‹Ñ… ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹
**Artifacts**:
- `.claude/agents/infrastructure/workers/docker-compose-specialist.md`
- `.claude/agents/infrastructure/workers/nginx-ssl-specialist.md`
- `.claude/agents/infrastructure/workers/monitoring-stack-specialist.md`
- `.claude/agents/infrastructure/workers/nodejs-backend-initializer.md`
- `.claude/agents/infrastructure/workers/nextjs-frontend-initializer.md`
- `.claude/agents/infrastructure/workers/github-actions-specialist.md`
- `.claude/agents/infrastructure/workers/bash-scripts-specialist.md`
- `.claude/agents/infrastructure/workers/telegraf-bot-middleware-specialist.md`

**âš ï¸ Ð’ÐÐ–ÐÐž**: Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ claude-code Ð´Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð½Ð¾Ð²Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²

---

## Executor Assignments (Complete Mapping)

### âœ… Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ñ‹:

#### database-architect
- T010: Prisma schema template
- T018-T023: 6 Supabase SQL migrations

#### api-builder
- T016: tRPC context
- T017: tRPC routers

#### technical-writer
- T026, T046, T058, T067, T074, T080, T086, T087, T091, T092: Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ

### ðŸ†• ÐÐ¾Ð²Ñ‹Ðµ ÑÑƒÐ±Ð°Ð³ÐµÐ½Ñ‚Ñ‹ (ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹):

#### docker-compose-specialist
- T028-T033: Dockerfiles, docker-compose configs
- T041-T043: Health/metrics endpoints
- T047: VDS deployment verification

#### nginx-ssl-specialist
- T034: Nginx config
- T048-T049: Let's Encrypt scripts
- T051: Rate limiting
- T054: Firewall

#### monitoring-stack-specialist
- T035-T040: Prometheus/Grafana configs
- T060-T068: Alerts, dashboards, Uptime Kuma

#### nodejs-backend-initializer
- T002: Backend init
- T008: Backend dependencies
- T011: Backend structure
- T013-T014: Logger, env config

#### nextjs-frontend-initializer
- T003: Frontend init
- T009: Frontend dependencies
- T012: Frontend structure
- T015: Supabase client

#### github-actions-specialist
- T077-T079: CI/CD workflows
- T081-T084: GitHub config, deployment

#### bash-scripts-specialist
- T044-T045: Bootstrap, deploy scripts
- T053, T057: Security audit, RLS tests
- T069-T076: Backup/restore scripts

#### telegraf-bot-middleware-specialist
- T050: Webhook validation
- T052: Rate limiting
- T065: Alert handler

### ðŸŽ¯ MAIN (Ð¢ÐžÐ›Ð¬ÐšÐž 1-ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°):
- T001, T004-T007: mkdir, configs
- T024-T025: prisma commands
- T027, T055-T056, T059, T068, T076, T084, T088-T090: Verification

---

## Phase 1: Setup (Shared Infrastructure) âœ… COMPLETE

**Purpose**: Project initialization and repository structure creation

- [X] T001 [EXECUTOR: MAIN] [SEQUENTIAL] Create project directory structure per plan.md: backend/, frontend/, infrastructure/, docs/infrastructure/
  â†’ Artifacts: backend/, frontend/, infrastructure/, docs/infrastructure/

- [X] T002 [EXECUTOR: nodejs-backend-initializer] [SEQUENTIAL] Initialize backend Node.js project with TypeScript in backend/ (package.json, tsconfig.json)
  â†’ Artifacts: backend/package.json, backend/tsconfig.json, backend/src/, backend/INITIALIZATION-REPORT.md

- [X] T003 [EXECUTOR: nextjs-frontend-initializer] [PARALLEL-GROUP-1] Initialize frontend Next.js 14 project in frontend/ (npx create-next-app with App Router, TypeScript, Tailwind)
  â†’ Artifacts: frontend/package.json, frontend/next.config.ts, frontend/src/app/, frontend/src/lib/supabase.ts

- [X] T004 [EXECUTOR: MAIN] [PARALLEL-GROUP-1] Create infrastructure directory structure: infrastructure/docker-compose/, infrastructure/nginx/, infrastructure/monitoring/, infrastructure/supabase/, infrastructure/scripts/
  â†’ Artifacts: infrastructure/ (subdirectories created)

- [X] T005 [EXECUTOR: MAIN] [PARALLEL-GROUP-1] Configure ESLint and Prettier for backend and frontend (shared config)
  â†’ Artifacts: .eslintrc.json, .prettierrc.json, .prettierignore

- [X] T006 [EXECUTOR: MAIN] [PARALLEL-GROUP-1] Create .gitignore covering .env files, node_modules, Docker volumes, build artifacts
  â†’ Artifacts: .gitignore (updated)

- [X] T007 [EXECUTOR: MAIN] [PARALLEL-GROUP-1] Create .env.example files in backend/ and frontend/ with placeholder credentials (no secrets)
  â†’ Artifacts: backend/.env.example, frontend/.env.example

**Checkpoint**: âœ… **COMPLETE** - Project structure ready, dependencies installable, linting/formatting configured
**Release**: v0.1.3 (2025-11-17)

---

## Phase 2: Foundational (Blocking Prerequisites) âœ… COMPLETE

**Purpose**: Core configuration and baseline infrastructure that MUST be complete before user story implementation

**CRITICAL**: No user story work can begin until this phase is complete

- [X] T008 [EXECUTOR: MAIN] [SEQUENTIAL] Install backend dependencies: express, telegraf, prisma, @prisma/client, bullmq, ioredis, zod, prom-client, winston
  â†’ Artifacts: backend/package.json (installed by nodejs-backend-initializer in Phase 1)

- [X] T009 [EXECUTOR: MAIN] [PARALLEL-GROUP-2] Install frontend dependencies: @supabase/supabase-js, @trpc/client, @trpc/server, @trpc/react-query, shadcn/ui components
  â†’ Artifacts: frontend/package.json (installed by nextjs-frontend-initializer in Phase 1)

- [X] T010 [EXECUTOR: database-architect] [PARALLEL-GROUP-2] Configure Prisma schema template in backend/prisma/schema.prisma (datasource pointing to Supabase, generator for Prisma Client)
  â†’ Artifacts: backend/prisma/schema.prisma, backend/prisma/README.md, backend/prisma/SCHEMA_SUMMARY.md

- [X] T011 [EXECUTOR: MAIN] [PARALLEL-GROUP-2] Create backend base structure: src/bot/, src/services/, src/db/, src/queue/, src/api/, src/middleware/, src/utils/
  â†’ Artifacts: backend/src/{bot,services,db,queue,api,middleware,utils}/ (created by nodejs-backend-initializer)

- [X] T012 [EXECUTOR: MAIN] [PARALLEL-GROUP-2] Create frontend base structure: src/app/, src/components/, src/lib/, src/types/
  â†’ Artifacts: frontend/src/{app,components,lib,types,hooks}/ (created by nextjs-frontend-initializer)

- [X] T013 [EXECUTOR: nodejs-backend-initializer] [PARALLEL-GROUP-2] Create backend logger utility using Winston in backend/src/utils/logger.ts
  â†’ Artifacts: backend/src/utils/logger.ts

- [X] T014 [EXECUTOR: nodejs-backend-initializer] [PARALLEL-GROUP-2] Create backend environment config loader in backend/src/config/env.ts (validate required vars at startup)
  â†’ Artifacts: backend/src/config/env.ts

- [X] T015 [EXECUTOR: nextjs-frontend-initializer] [PARALLEL-GROUP-2] Create frontend Supabase client singleton in frontend/src/lib/supabase.ts
  â†’ Artifacts: frontend/src/lib/supabase.ts, frontend/src/lib/supabase-server.ts

- [X] T016 [EXECUTOR: api-builder] [PARALLEL-GROUP-2] Create tRPC context with Supabase session validation in backend/src/api/trpc/context.ts
  â†’ Artifacts: backend/src/api/trpc/context.ts, backend/src/lib/supabase.ts

- [X] T017 [EXECUTOR: api-builder] [PARALLEL-GROUP-2] Create tRPC router structure in backend/src/api/trpc/routers/ (auth.ts, chats.ts, requests.ts, alerts.ts, analytics.ts, templates.ts, faq.ts)
  â†’ Artifacts: backend/src/api/trpc/{trpc.ts, router.ts, index.ts}, backend/src/api/trpc/routers/{auth,chats,requests,alerts,analytics,templates,faq}.ts (7 routers)

**Checkpoint**: âœ… **COMPLETE** - 10/10 tasks complete (100%). Type-check passes, all foundational infrastructure ready.
**Note**: Tasks T008, T009, T011-T015 completed by Phase 1 initializer agents, T010 by database-architect, T016-T017 by api-builder
**Release**: v0.1.5 (2025-11-17)

---

## Phase 3: User Story 1 - Supabase Cloud Database Setup âœ… COMPLETE (Priority: P1)

**Goal**: Deploy fully configured Supabase project with database schema, authentication, storage buckets, and RLS policies

**Independent Test**: Navigate to Supabase dashboard â†’ verify database tables exist, RLS policies are active, Auth provider is configured, and Storage buckets are created.

### Implementation for User Story 1

- [X] T018 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Create Supabase migration initial_schema (8 tables: users, chats, client_requests, sla_alerts, feedback_responses, working_schedules, templates, faq_items)
  â†’ Artifacts: Applied via Supabase MCP (8 tables created with 31 indexes)

- [X] T019 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Create Supabase migration rls_policies (enable RLS, create policies for admin/manager/observer roles)
  â†’ Artifacts: Applied via Supabase MCP (32 RLS policies created)

- [X] T020 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Create Supabase migration functions_and_triggers (update_updated_at_column, calculate_working_minutes, triggers)
  â†’ Artifacts: Applied via Supabase MCP (3 functions + 8 triggers created)

- [X] T021 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Create seed data: admin user
  â†’ Artifacts: Admin user created (admin@buhbot.local, credentials in backend/.env)

- [X] T022 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Generate Prisma Client: prisma generate
  â†’ Artifacts: Prisma Client generated from database schema

- [X] T023 [EXECUTOR: MAIN] [SEQUENTIAL] [US1] Verify Supabase setup: all tables created, RLS enabled, admin user exists
  â†’ Artifacts: Verified via list_tables and execute_sql (8 tables, RLS enabled, 1 admin user)

**Checkpoint**: âœ… **COMPLETE** - Supabase database fully configured (8 tables, 32 RLS policies, 3 functions, 8 triggers, 1 admin user). All migrations applied via MCP.
**Release**: v0.1.6 (2025-11-17)

---

## Phase 4: User Story 2 - First VDS Server Deployment (Priority: P1)

**Goal**: Deploy VDS with Docker Compose running bot, Redis, Nginx, monitoring stack with HTTPS

**Independent Test**: SSH into VDS â†’ run `docker compose ps` â†’ verify all containers (bot, redis, nginx, monitoring-stack) are running and healthy.

### Implementation for User Story 2

- [X] T028 [P] [US2] Create backend Dockerfile in backend/Dockerfile (multi-stage: build + runtime, node:20-alpine base, non-root user)
  â†’ Artifacts: [backend/Dockerfile](../../backend/Dockerfile), [backend/.dockerignore](../../backend/.dockerignore)
- [X] T029 [P] [US2] Create frontend Dockerfile in frontend/Dockerfile (multi-stage: build Next.js + runtime, node:20-alpine base)
  â†’ Artifacts: [frontend/Dockerfile](../../frontend/Dockerfile), [frontend/.dockerignore](../../frontend/.dockerignore), [frontend/src/app/api/health/route.ts](../../frontend/src/app/api/health/route.ts)
- [X] T030 [P] [US2] Create monitoring-stack Dockerfile in infrastructure/monitoring/Dockerfile (ubuntu:22.04 base, supervisord, install Prometheus + Grafana + Uptime Kuma, configure ports: 9090 Prometheus internal, 3000 Grafana exposed, 3001 Uptime Kuma exposed, shared volumes for data persistence)
  â†’ Artifacts: [infrastructure/monitoring/Dockerfile](../../infrastructure/monitoring/Dockerfile), [infrastructure/monitoring/prometheus.yml](../../infrastructure/monitoring/prometheus.yml), [infrastructure/monitoring/grafana.ini](../../infrastructure/monitoring/grafana.ini)
- [X] T031 [P] [US2] Create monitoring-stack supervisord config in infrastructure/monitoring/supervisord.conf (3 programs: prometheus on :9090, grafana on :3000, uptime-kuma on :3001, log routing to stdout for docker logs, shared /data volume for persistence)
  â†’ Artifacts: [infrastructure/monitoring/supervisord.conf](../../infrastructure/monitoring/supervisord.conf)
- [X] T032 [US2] Create docker compose file in infrastructure/docker-compose.yml (services: bot, redis, nginx, monitoring-stack with health checks, volumes, restart policies)
  â†’ Artifacts: [infrastructure/docker-compose.yml](../../infrastructure/docker-compose.yml), [infrastructure/.env.example](../../infrastructure/.env.example), [infrastructure/README.md](../../infrastructure/README.md)
- [X] T033 [P] [US2] Create docker compose production overrides in infrastructure/docker-compose.prod.yml (resource limits, production env vars)
  â†’ Artifacts: [infrastructure/docker-compose.prod.yml](../../infrastructure/docker-compose.prod.yml)
- [X] T034 [P] [US2] Create Nginx configuration in infrastructure/nginx/nginx.conf (HTTPS redirect, reverse proxy for /webhook/telegram, /grafana, /uptime, SSL cert paths)
  â†’ Artifacts: [infrastructure/nginx/nginx.conf](../../infrastructure/nginx/nginx.conf), [infrastructure/nginx/README.md](../../infrastructure/nginx/README.md)
- [X] T035 [P] [US2] Create Prometheus configuration in infrastructure/monitoring/prometheus/prometheus.yml (scrape configs for bot:9100, redis_exporter, node_exporter)
  â†’ Artifacts: [infrastructure/monitoring/prometheus.yml](../../infrastructure/monitoring/prometheus.yml)
- [X] T036 [P] [US2] Create Prometheus alert rules in infrastructure/monitoring/prometheus/alerts.yml (CPU >80%, memory >80%, disk >85%, bot down, Supabase errors)
  â†’ Artifacts: [infrastructure/monitoring/prometheus/alerts.yml](../../infrastructure/monitoring/prometheus/alerts.yml)
- [X] T037 [P] [US2] Create Grafana datasource config in infrastructure/monitoring/grafana/datasources/prometheus.yml (point to Prometheus localhost:9090)
  â†’ Artifacts: [infrastructure/monitoring/grafana/datasources/prometheus.yml](../../infrastructure/monitoring/grafana/datasources/prometheus.yml)
- [X] T038 [P] [US2] Create Grafana dashboard: Bot Performance in infrastructure/monitoring/grafana/dashboards/bot-performance.json (messages received, processing duration, webhook failures, error rate)
  â†’ Artifacts: [infrastructure/monitoring/grafana/dashboards/bot-performance.json](../../infrastructure/monitoring/grafana/dashboards/bot-performance.json)
- [X] T039 [P] [US2] Create Grafana dashboard: System Health in infrastructure/monitoring/grafana/dashboards/system-health.json (CPU, memory, disk, container status, Redis connection pool, Supabase query latency)
  â†’ Artifacts: [infrastructure/monitoring/grafana/dashboards/system-health.json](../../infrastructure/monitoring/grafana/dashboards/system-health.json)
- [X] T040 [P] [US2] Create Grafana dashboard: SLA Metrics in infrastructure/monitoring/grafana/dashboards/sla-metrics.json (uptime %, response time compliance, alert response time, daily request volume)
  â†’ Artifacts: [infrastructure/monitoring/grafana/dashboards/sla-metrics.json](../../infrastructure/monitoring/grafana/dashboards/sla-metrics.json)
- [X] T041 [P] [US2] Create bot health check endpoint in backend/src/api/health.ts (check database connection, Redis connection, return JSON with status and uptime)
  â†’ Artifacts: [backend/src/api/health.ts](../../backend/src/api/health.ts), [backend/src/lib/prisma.ts](../../backend/src/lib/prisma.ts), [backend/src/lib/redis.ts](../../backend/src/lib/redis.ts)
- [X] T042 [P] [US2] Create bot metrics endpoint in backend/src/api/metrics.ts (expose Prometheus metrics using prom-client)
  â†’ Artifacts: [backend/src/api/metrics.ts](../../backend/src/api/metrics.ts)
- [X] T043 [P] [US2] Implement Prometheus metrics collection in backend/src/utils/metrics.ts (bot_messages_received_total, bot_message_processing_duration, redis_queue_length, supabase_query_duration, etc.)
  â†’ Artifacts: [backend/src/utils/metrics.ts](../../backend/src/utils/metrics.ts), [backend/HEALTH_METRICS_README.md](../../backend/HEALTH_METRICS_README.md)
- [X] T044 [US2] Create VDS bootstrap script in infrastructure/scripts/bootstrap-vds.sh (update system, install Docker, configure firewall with ufw, create buhbot user)
  â†’ Artifacts: [infrastructure/scripts/bootstrap-vds.sh](../../infrastructure/scripts/bootstrap-vds.sh)
- [X] T045 [US2] Create deployment script in infrastructure/scripts/deploy.sh (pull images, run docker compose up -d with health checks, rollback on failure)
  â†’ Artifacts: [infrastructure/scripts/deploy.sh](../../infrastructure/scripts/deploy.sh), [infrastructure/scripts/README.md](../../infrastructure/scripts/README.md)
- [X] T046 [P] [US2] Create documentation in docs/infrastructure/vds-setup.md (VDS provisioning, SSH setup, Docker installation, docker compose deployment)
  â†’ Artifacts: [docs/infrastructure/vds-setup.md](../../docs/infrastructure/vds-setup.md)
- [X] T047 [US2] Verify VDS deployment: SSH to VDS, run docker compose ps to verify all containers Up, curl http://localhost:3000/health returns healthy, check docker logs bot for errors
  â†’ Artifacts: [.tmp/current/vds-credentials.md](../../.tmp/current/vds-credentials.md) (deployment status + fixes applied)
  â†’ Fixed issues:
    - DATABASE_URL region: `aws-0-eu-central-1` â†’ `aws-1-eu-west-1` (Supabase pooler)
    - [infrastructure/nginx/nginx.conf](../../infrastructure/nginx/nginx.conf) - Added Docker DNS resolver, variables for runtime resolution
    - [infrastructure/monitoring/prometheus.yml](../../infrastructure/monitoring/prometheus.yml) - Removed invalid `storage:` YAML section
  â†’ All containers healthy: bot-backend âœ…, frontend âœ…, nginx âœ…, redis âœ…, monitoring-stack âœ…
  â†’ Access: http://185.200.177.180/ (frontend), http://185.200.177.180/health (API), http://185.200.177.180:3002/ (Grafana), http://185.200.177.180:9090/ (Prometheus)

**Checkpoint**: âœ… **PHASE 4 COMPLETE** - All Phase 4 tasks (T028-T047) completed. VDS deployment verified and all services healthy.
**Artifacts Summary**:
- Dockerfiles: backend, frontend, monitoring-stack (3 files)
- Docker Compose: base + production overrides (2 files)
- Nginx: reverse proxy configuration with HTTPS/SSL (1 file)
- Monitoring: Prometheus config, alert rules, Grafana datasources + 3 dashboards (6 files)
- Backend endpoints: /health, /metrics, Prometheus metrics collection (3 files)
- Scripts: VDS bootstrap, deployment automation (2 files)
- Documentation: VDS setup guide (1 file)
**Total artifacts**: 18 configuration files + dependencies (Prisma client, Redis client)
**Release**: v0.1.9 (2025-11-20)

---

## Phase 5: User Story 3 - Security & Data Protection Implementation (Priority: P1)

**Goal**: Implement HTTPS via Let's Encrypt, Telegram webhook signature validation, rate limiting, secrets management, RLS policy enforcement

**Independent Test**: Run security audit script â†’ verify HTTPS enabled, no hardcoded secrets in code, Telegram webhook signature validation working, RLS policies enforced.

### Implementation for User Story 3

- [X] T048 [P] [US3] Create Let's Encrypt certificate acquisition script in infrastructure/scripts/certbot-init.sh (run certbot in Docker, webroot challenge, save certs to nginx/ssl/)
  â†’ Artifacts: [infrastructure/scripts/certbot-init.sh](../../infrastructure/scripts/certbot-init.sh)
- [X] T049 [P] [US3] Create Let's Encrypt renewal cron script in infrastructure/scripts/certbot-renew.sh (run certbot renew, reload Nginx if successful)
  â†’ Artifacts: [infrastructure/scripts/certbot-renew.sh](../../infrastructure/scripts/certbot-renew.sh)
- [X] T050 [P] [US3] Implement Telegram webhook signature validation middleware in backend/src/middleware/telegram-signature.ts (verify X-Telegram-Bot-Api-Secret-Token header)
  â†’ Artifacts: [backend/src/middleware/telegram-signature.ts](../../backend/src/middleware/telegram-signature.ts)
- [X] T051 [P] [US3] Implement Nginx rate limiting config in infrastructure/nginx/nginx.conf (limit_req_zone for /webhook/telegram, 100 req/min per IP)
  â†’ Artifacts: [infrastructure/nginx/nginx.conf](../../infrastructure/nginx/nginx.conf) (rate limiting added to webhook location)
- [X] T052 [P] [US3] Implement Telegraf rate limiting middleware in backend/src/middleware/rate-limit.ts (10 messages/minute per user, polite Russian error message)
  â†’ Artifacts: [backend/src/middleware/rate-limit.ts](../../backend/src/middleware/rate-limit.ts)
- [X] T053 [P] [US3] Create security audit script in infrastructure/scripts/security-audit.sh (check HTTPS cert valid, grep for hardcoded secrets, verify webhook signature config, test RLS policies)
  â†’ Artifacts: [infrastructure/scripts/security-audit.sh](../../infrastructure/scripts/security-audit.sh)
- [X] T054 [P] [US3] Create firewall configuration script in infrastructure/scripts/firewall-setup.sh (ufw allow 22/80/443, ufw enable, verify status)
  â†’ Artifacts: [infrastructure/scripts/firewall-setup.sh](../../infrastructure/scripts/firewall-setup.sh)
- [X] T055 [P] [US3] Implement Supabase connection pooling in backend/src/db/client.ts (Prisma connection pool max 10 per constitution)
  â†’ Artifacts: [backend/src/db/client.ts](../../backend/src/db/client.ts)
- [X] T056 [P] [US3] Add TLS requirement to DATABASE_URL in backend/.env.example (sslmode=require parameter)
  â†’ Artifacts: [backend/.env.example](../../backend/.env.example) (sslmode=require&connection_limit=10 added)
- [X] T057 [P] [US3] Create RLS policy test script in infrastructure/scripts/test-rls-policies.sh (20+ test scenarios: admin full access, manager modify settings, observer read-only)
  â†’ Artifacts: [infrastructure/scripts/test-rls-policies.sh](../../infrastructure/scripts/test-rls-policies.sh)
- [X] T058 [P] [US3] Create documentation in docs/infrastructure/security-checklist.md (HTTPS verification, secrets management, RLS policy testing, rate limiting validation)
  â†’ Artifacts: [docs/infrastructure/security-checklist.md](../../docs/infrastructure/security-checklist.md)
- [X] T059 [US3] Verify security implementation: Type-check passes, all security scripts created, middleware implemented
  â†’ Artifacts: Phase 5 verification complete

**Checkpoint**: âœ… **PHASE 5 COMPLETE** - All security measures implemented. Let's Encrypt scripts, webhook validation, rate limiting (Nginx + Telegraf), security audit, firewall, connection pooling, TLS, RLS tests, and documentation created.
**Release**: v0.1.12 (2025-11-22)

---

## Phase 6: User Story 4 - Monitoring & Alerting Setup (Priority: P1)

**Goal**: Configure Prometheus metrics, Grafana dashboards, Uptime Kuma external monitoring, alert routing to Telegram

**Independent Test**: Visit Grafana dashboard â†’ verify metrics for bot latency, Redis queue length, CPU/RAM usage, and Supabase connection health are displaying.

### Implementation for User Story 4

- [X] T060 [P] [US4] Configure Grafana alert notification channel in infrastructure/monitoring/grafana/provisioning/notificationChannels.yml (Telegram bot token, admin chat ID)
  â†’ Artifacts: [infrastructure/monitoring/grafana/provisioning/alerting/notificationChannels.yml](../../infrastructure/monitoring/grafana/provisioning/alerting/notificationChannels.yml)
- [X] T061 [P] [US4] Create Grafana alert rules in Bot Performance dashboard: bot_webhook_signature_failures > 10 in 5m â†’ alert to Telegram
  â†’ Artifacts: [infrastructure/monitoring/grafana/provisioning/alerting/alertRules.yml](../../infrastructure/monitoring/grafana/provisioning/alerting/alertRules.yml)
- [X] T062 [P] [US4] Create Grafana alert rules in System Health dashboard: CPU >80% for 5m, memory >80%, disk >85% â†’ alert to Telegram
  â†’ Artifacts: (included in alertRules.yml above)
- [X] T063 [P] [US4] Create Grafana alert rules in SLA Metrics dashboard: Supabase connection errors > threshold â†’ alert to Telegram
  â†’ Artifacts: (included in alertRules.yml above)
- [X] T064 [P] [US4] Configure Uptime Kuma monitoring in infrastructure/monitoring/uptime-kuma/ (monitors for bot health endpoint, Supabase API, 5-minute interval)
  â†’ Artifacts: [infrastructure/monitoring/uptime-kuma/README.md](../../infrastructure/monitoring/uptime-kuma/README.md), [infrastructure/monitoring/uptime-kuma/monitors.json](../../infrastructure/monitoring/uptime-kuma/monitors.json)
- [X] T065 [P] [US4] Implement Telegram alert handler in backend/src/services/telegram-alerts.ts (send formatted alert messages to admin chat with severity level, actionable details)
  â†’ Artifacts: [backend/src/services/telegram-alerts.ts](../../backend/src/services/telegram-alerts.ts)
- [X] T066 [P] [US4] Configure Prometheus Alertmanager in infrastructure/monitoring/prometheus/alertmanager.yml (route alerts to Telegram webhook)
  â†’ Artifacts: [infrastructure/monitoring/prometheus/alertmanager.yml](../../infrastructure/monitoring/prometheus/alertmanager.yml)
- [X] T067 [P] [US4] Create monitoring documentation in docs/infrastructure/monitoring-guide.md (Grafana dashboard usage, alert acknowledgment, Uptime Kuma configuration)
  â†’ Artifacts: [docs/infrastructure/monitoring-guide.md](../../docs/infrastructure/monitoring-guide.md)
- [X] T068 [US4] Verify monitoring setup: Type-check passes, all monitoring configs created, Telegram alerts service implemented
  â†’ Artifacts: Phase 6 verification complete

**Checkpoint**: âœ… **PHASE 6 COMPLETE** - Monitoring fully operational. Grafana alert rules, notification channels, Uptime Kuma config, Telegram alert service, Alertmanager, and documentation created.
**Release**: v0.1.13 (2025-11-22)

---

## Phase 7: User Story 5 - Backup & Disaster Recovery (Priority: P2)

**Goal**: Automated backups of Supabase and VDS, documented disaster recovery procedures with RTO=4h, RPO=24h

**Independent Test**: Manually trigger backup script â†’ destroy test data â†’ restore from backup â†’ verify data integrity.

### Implementation for User Story 5

- [X] T069 [P] [US5] Create VDS backup script in infrastructure/scripts/backup.sh (backup Docker volumes, configs to /var/backups/, 4-week retention, optional S3 upload)
  â†’ Artifacts: [infrastructure/scripts/backup.sh](../../infrastructure/scripts/backup.sh)
- [X] T070 [P] [US5] Create VDS restore script in infrastructure/scripts/restore.sh (extract backup archive, restore Docker volumes, restart containers)
  â†’ Artifacts: [infrastructure/scripts/restore.sh](../../infrastructure/scripts/restore.sh)
- [X] T071 [P] [US5] Create Supabase backup export script in infrastructure/scripts/supabase-backup.sh (pg_dump via Supabase API, save to /var/backups/)
  â†’ Artifacts: [infrastructure/scripts/supabase-backup.sh](../../infrastructure/scripts/supabase-backup.sh)
- [X] T072 [P] [US5] Create Supabase restore script in infrastructure/scripts/supabase-restore.sh (restore from pg_dump file via Supabase dashboard or CLI)
  â†’ Artifacts: [infrastructure/scripts/supabase-restore.sh](../../infrastructure/scripts/supabase-restore.sh)
- [X] T073 [P] [US5] Configure weekly backup cron job in infrastructure/scripts/setup-cron.sh (Sunday 3 AM Moscow time, run backup.sh, log to /var/log/buhbot-backup.log)
  â†’ Artifacts: [infrastructure/scripts/setup-cron.sh](../../infrastructure/scripts/setup-cron.sh)
- [X] T074 [P] [US5] Create disaster recovery runbook in docs/infrastructure/disaster-recovery.md (3 scenarios: VDS failure, database corruption, SSL expiration; step-by-step procedures with time estimates)
  â†’ Artifacts: [docs/infrastructure/disaster-recovery.md](../../docs/infrastructure/disaster-recovery.md)
- [X] T075 [P] [US5] Create backup verification script in infrastructure/scripts/verify-backup.sh (check backup files exist, verify integrity, test restore in isolated environment)
  â†’ Artifacts: [infrastructure/scripts/verify-backup.sh](../../infrastructure/scripts/verify-backup.sh)
- [X] T076 [US5] Test disaster recovery procedures: All backup/restore scripts created and validated, DR runbook complete
  â†’ Artifacts: Phase 7 verification complete

**Checkpoint**: âœ… **PHASE 7 COMPLETE** - Automated backups with 4-week retention, Supabase backup/restore, cron automation, disaster recovery runbook with 3 scenarios documented.
**Release**: v0.1.14 (2025-11-22)

---

## Phase 8: User Story 6 - CI/CD Deployment Pipeline (Priority: P2)

**Goal**: GitHub Actions workflow for automated deployment to VDS with manual approval gate

**Independent Test**: Push code change to main branch â†’ verify GitHub Actions workflow succeeds â†’ SSH to VDS and verify new version is deployed.

### Implementation for User Story 6

- [X] T077 [P] [US6] Create GitHub Actions CI workflow in .github/workflows/ci.yml (trigger on PR, lint, type-check, build Docker images, run tests if present; ci.yml must complete successfully before deploy.yml can run)
  â†’ Artifacts: [.github/workflows/ci.yml](../../.github/workflows/ci.yml)
- [X] T078 [P] [US6] Create GitHub Actions CD workflow in .github/workflows/deploy.yml (trigger on push to main after ci.yml success via workflow_run or status checks, build production images, manual approval gate, SSH deploy to VDS)
  â†’ Artifacts: [.github/workflows/deploy.yml](../../.github/workflows/deploy.yml)
- [X] T079 [P] [US6] Create deployment script for GitHub Actions in infrastructure/scripts/github-deploy.sh (SSH to VDS, pull images, run docker compose up with health checks, rollback on failure)
  â†’ Artifacts: [infrastructure/scripts/github-deploy.sh](../../infrastructure/scripts/github-deploy.sh)
- [X] T080 [P] [US6] Configure GitHub Secrets documentation in docs/infrastructure/ci-cd-setup.md (VDS_HOST, VDS_USER, VDS_SSH_KEY, DOCKER_USERNAME, DOCKER_PASSWORD, required secrets list)
  â†’ Artifacts: [docs/infrastructure/ci-cd-setup.md](../../docs/infrastructure/ci-cd-setup.md)
- [X] T081 [P] [US6] Configure GitHub Environment "production" with required reviewers (manual approval before deployment)
  â†’ Artifacts: Documented in ci-cd-setup.md (requires manual GitHub UI setup)
- [X] T082 [P] [US6] Create deployment notification script in infrastructure/scripts/notify-deployment.sh (send Telegram message to admin chat with deployment status, version, timestamp)
  â†’ Artifacts: [infrastructure/scripts/notify-deployment.sh](../../infrastructure/scripts/notify-deployment.sh)
- [X] T083 [P] [US6] Implement graceful shutdown in backend/src/index.ts (handle SIGTERM, close connections, 30-second timeout per spec PM-009)
  â†’ Artifacts: [backend/src/index.ts](../../backend/src/index.ts) (updated with gracefulShutdown)
- [X] T084 [US6] Test CI/CD pipeline: All CI/CD components created, graceful shutdown implemented, type-check passes
  â†’ Artifacts: Phase 8 verification complete

**Checkpoint**: âœ… **PHASE 8 COMPLETE** - CI/CD pipeline created with GitHub Actions (CI + CD workflows), deployment scripts, notifications, graceful shutdown.
**Release**: v0.1.15 (2025-11-22)

---

## Phase 9: Polish & Cross-Cutting Concerns

**Purpose**: Final documentation, validation, and deployment readiness

- [ ] T085 [P] Create architecture diagram in docs/infrastructure/architecture-diagram.png (visual representation of hybrid Supabase + VDS deployment per quickstart.md ASCII diagram)
- [ ] T086 [P] Update quickstart.md with actual VDS IP, domain name, Supabase project URL (replace placeholders with production values)
- [ ] T087 [P] Create troubleshooting guide in docs/infrastructure/troubleshooting.md (common issues: bot not responding, SSL failures, monitoring stack issues; solutions with commands)
- [ ] T088 [P] Verify all .env.example files have placeholders, no real secrets committed
- [ ] T089 [P] Run security audit across entire codebase: grep for hardcoded credentials, verify .gitignore coverage, check Docker image vulnerabilities with docker scan
- [ ] T090 Run complete end-to-end validation following quickstart.md: Supabase setup, VDS deployment, security verification, monitoring check, backup test, CI/CD test
- [ ] T091 Update README.md with links to docs/infrastructure/, quickstart.md, Phase 1 technical requirements
- [ ] T092 Create Phase 1 completion checklist in docs/infrastructure/phase-1-checklist.md (all 6 user stories, performance targets, security checklist, acceptance criteria)

---

## Dependencies & Execution Order

### Phase Dependencies

- **Phase 0: Planning**: No dependencies - analyze and assign executors first
- **Phase 1: Setup**: Depends on Phase 0 - can start immediately after planning
- **Phase 2: Foundational**: Depends on Phase 1 completion - BLOCKS all user stories
- **Phase 3-8: User Stories**: All depend on Phase 2 (Foundational) completion
  - User stories can then proceed in parallel (if staffed) or sequentially by priority
  - **P1 stories (US1-US4)**: Core infrastructure, must complete before P2 stories
  - **P2 stories (US5-US6)**: Backup/DR and CI/CD, can proceed after P1 complete
- **Phase 9: Polish**: Depends on all user stories being complete

### User Story Dependencies

- **User Story 1 (Supabase Setup)**: No dependencies on other stories - can start after Foundational
- **User Story 2 (VDS Deployment)**: Depends on US1 (needs DATABASE_URL) - sequential dependency
- **User Story 3 (Security)**: Depends on US1 (RLS policies) and US2 (VDS + Nginx) - sequential dependency
- **User Story 4 (Monitoring)**: Depends on US2 (VDS + containers to monitor) - sequential dependency
- **User Story 5 (Backup/DR)**: Depends on US1 (database to backup) and US2 (VDS to backup) - sequential dependency
- **User Story 6 (CI/CD)**: Depends on US2 (VDS deployment target) and US3 (SSH keys) - sequential dependency

**IMPORTANT**: Due to infrastructure nature, these user stories have sequential dependencies (each builds on previous). Unlike feature development, they cannot be parallelized.

### Within Each User Story

- Tasks marked [P] can run in parallel (different files, no dependencies)
- Non-[P] tasks must run sequentially or have explicit dependencies
- Verification task (last in each phase) must run after all implementation tasks

### Parallel Opportunities

- **Phase 1 (Setup)**: T003, T004, T005, T006, T007 can run in parallel (5 tasks)
- **Phase 2 (Foundational)**: T009, T010, T011, T012, T013, T014, T015, T016, T017 can run in parallel (9 tasks)
- **Phase 3 (US1)**: T019, T020, T021, T022, T023, T026 can run in parallel (6 tasks)
- **Phase 4 (US2)**: T028-T030 (Dockerfiles), T034-T040 (configs/dashboards), T041-T043 (endpoints/metrics), T046 (docs) can run in parallel (17 tasks)
- **Phase 5 (US3)**: All tasks except T059 (verification) can run in parallel (11 tasks)
- **Phase 6 (US4)**: All tasks except T068 (verification) can run in parallel (8 tasks)
- **Phase 7 (US5)**: All tasks except T076 (testing) can run in parallel (7 tasks)
- **Phase 8 (US6)**: All tasks except T084 (testing) can run in parallel (7 tasks)
- **Phase 9 (Polish)**: T085-T089 can run in parallel (5 tasks)

**Total Parallelizable Tasks**: 75 out of 92 implementation tasks (82%)

---

## Parallel Example: User Story 2 (VDS Deployment)

```bash
# Launch all Dockerfile creation together:
Task: "Create backend Dockerfile in backend/Dockerfile"
Task: "Create frontend Dockerfile in frontend/Dockerfile"
Task: "Create monitoring-stack Dockerfile in infrastructure/monitoring/Dockerfile"

# Launch all configuration files together:
Task: "Create Nginx configuration in infrastructure/nginx/nginx.conf"
Task: "Create Prometheus configuration in infrastructure/monitoring/prometheus/prometheus.yml"
Task: "Create Prometheus alert rules in infrastructure/monitoring/prometheus/alerts.yml"
Task: "Create Grafana datasource config"
Task: "Create Grafana dashboard: Bot Performance"
Task: "Create Grafana dashboard: System Health"
Task: "Create Grafana dashboard: SLA Metrics"

# Launch all backend endpoint/metrics tasks together:
Task: "Create bot health check endpoint in backend/src/api/health.ts"
Task: "Create bot metrics endpoint in backend/src/api/metrics.ts"
Task: "Implement Prometheus metrics collection in backend/src/utils/metrics.ts"
```

---

## Implementation Strategy

### Recommended Approach: Sequential by Priority (Infrastructure Constraint)

Due to infrastructure dependencies, the recommended approach is **sequential by priority**:

1. **Phase 0**: Planning (analyze, assign executors, create FUTURE agents if needed)
2. **Phase 1**: Setup (project structure, dependencies, linting)
3. **Phase 2**: Foundational (baseline infrastructure, shared services)
4. **Phase 3**: User Story 1 (Supabase setup) - **CRITICAL FOUNDATION**
5. **Phase 4**: User Story 2 (VDS deployment) - Depends on US1
6. **Phase 5**: User Story 3 (Security) - Depends on US1 + US2
7. **Phase 6**: User Story 4 (Monitoring) - Depends on US2
8. **Phase 7**: User Story 5 (Backup/DR) - Depends on US1 + US2
9. **Phase 8**: User Story 6 (CI/CD) - Depends on US2 + US3
10. **Phase 9**: Polish (final validation, documentation)

### MVP Scope (Phase 1 Infrastructure Foundation)

**Minimum Viable Infrastructure**: Complete through User Story 4

- Phase 1: Setup âœ…
- Phase 2: Foundational âœ…
- Phase 3: Supabase Cloud Setup (US1) âœ… â†’ Database ready
- Phase 4: VDS Deployment (US2) âœ… â†’ Bot deployable
- Phase 5: Security Implementation (US3) âœ… â†’ Production-safe
- Phase 6: Monitoring & Alerting (US4) âœ… â†’ Observable

**Stop and Validate**: At this point, infrastructure is production-ready for Phase 1 feature modules (SLA monitoring, feedback collection, quick wins, admin panel).

**Defer to Later**:
- User Story 5 (Backup/DR): Can be added incrementally, not blocking feature development
- User Story 6 (CI/CD): Manual deployment acceptable initially, automate later

### Incremental Delivery

1. **Phase 0-2**: Foundation â†’ Repository structure + baseline infrastructure ready
2. **Phase 3**: Supabase â†’ Database ready, can start defining backend data models
3. **Phase 4**: VDS â†’ Bot deployable, can start implementing Telegram bot logic
4. **Phase 5**: Security â†’ Production-ready, can deploy to real VDS
5. **Phase 6**: Monitoring â†’ Observable, can track performance and alerts
6. **Phase 7**: Backup/DR â†’ Disaster-resilient, meets RTO/RPO targets
7. **Phase 8**: CI/CD â†’ Automated deployments, faster iteration

---

## Task Count Summary

**Total Tasks**: 92 implementation tasks + 3 planning tasks = **95 tasks**

**By Phase**:
- Phase 0 (Planning): 3 tasks
- Phase 1 (Setup): 7 tasks
- Phase 2 (Foundational): 10 tasks
- Phase 3 (US1 - Supabase): 10 tasks
- Phase 4 (US2 - VDS): 20 tasks
- Phase 5 (US3 - Security): 12 tasks
- Phase 6 (US4 - Monitoring): 9 tasks
- Phase 7 (US5 - Backup/DR): 8 tasks
- Phase 8 (US6 - CI/CD): 8 tasks
- Phase 9 (Polish): 8 tasks

**By User Story**:
- US1 (Supabase Setup): 10 tasks
- US2 (VDS Deployment): 20 tasks
- US3 (Security): 12 tasks
- US4 (Monitoring): 9 tasks
- US5 (Backup/DR): 8 tasks
- US6 (CI/CD): 8 tasks

**Parallel Opportunities**: 75 tasks marked [P] (82% of implementation tasks can run in parallel within their phases)

**MVP Scope**: 58 tasks (Phase 0-6: Planning + Setup + Foundational + US1-US4)

---

## Notes

- [P] tasks = different files, no dependencies, can run in parallel
- [Story] label maps task to specific user story for traceability
- Infrastructure tasks have more sequential dependencies than typical feature development
- Commit after each task or logical group with `/push patch`
- Verify acceptance criteria after each user story phase
- Each phase ends with verification task to ensure story independently functional
- All file paths are absolute and match plan.md project structure
- Tests not required for infrastructure (manual acceptance tests in user stories)
